{"cells":[{"cell_type":"markdown","source":["# Mount drive"],"metadata":{"id":"e-WdB_EoUa79"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"ILnIFoqRA14o","colab":{"base_uri":"https://localhost:8080/"},"outputId":"78bbd74d-a101-4cfb-f311-a70caa037416","executionInfo":{"status":"ok","timestamp":1701075452452,"user_tz":-60,"elapsed":16310,"user":{"displayName":"Marco Calenda","userId":"01086435372740505866"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Import libraries"],"metadata":{"id":"ele-ZQMcoJkB"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import string\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.corpus import stopwords, wordnet\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","\n","# SEED for reproducibility\n","import random\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)"],"metadata":{"id":"hwAOBOmQqR6j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701075457664,"user_tz":-60,"elapsed":2967,"user":{"displayName":"Marco Calenda","userId":"01086435372740505866"}},"outputId":"98910aa4-5fcb-4b71-bc29-693055c9a4d3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"markdown","source":["# Load data"],"metadata":{"id":"nn-7tgvIoavo"}},{"cell_type":"code","source":["RAW_DATASET_1_PATH = '/content/drive/MyDrive/Tesi/Master-Thesis/data/external/PROMISE-reclass.csv'\n","RAW_DATASET_2_PATH = '/content/drive/MyDrive/Tesi/Master-Thesis/data/external/PROMISE-exp.csv'\n","\n","df_1 = pd.read_csv(RAW_DATASET_1_PATH)\n","df_2 = pd.read_csv(RAW_DATASET_2_PATH)\n","df = pd.concat([df_1, df_2], ignore_index=True)"],"metadata":{"id":"bFSiOPVKoYOH","executionInfo":{"status":"ok","timestamp":1701075460822,"user_tz":-60,"elapsed":1210,"user":{"displayName":"Marco Calenda","userId":"01086435372740505866"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Drop unused columns and rows"],"metadata":{"id":"8VhXddUOoy6q"}},{"cell_type":"code","source":["X_column = 'RequirementText'\n","y_column = 'Class'\n","\n","df[y_column].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1TEA_Ah_tvr","executionInfo":{"status":"ok","timestamp":1701075498334,"user_tz":-60,"elapsed":340,"user":{"displayName":"Marco Calenda","userId":"01086435372740505866"}},"outputId":"3e968c2e-4531-449f-c7f0-5f7947d77629"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["F     446\n","SE    125\n","US     85\n","O      77\n","PE     67\n","LF     49\n","A      31\n","MN     24\n","SC     22\n","FT     18\n","L      15\n","PO     12\n","Name: Class, dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["In this research study we focus on:\n","*   **SE**: security requirements;\n","*   **US**: usability requirements;\n","*   **O**: operational requirements;\n","*   **PE**: performance requirements."],"metadata":{"id":"-zAUJcT7_wHD"}},{"cell_type":"code","source":["to_drop_columns = ['ProjectID', 'IsFunctional', 'IsQuality']\n","df = df.drop(to_drop_columns, axis=1)\n","\n","to_drop_classes = {'LF', 'SC', 'A', 'MN', 'L', 'FT', 'PO', 'F'}\n","mask = ~df[y_column].isin(to_drop_classes)\n","df = df[mask]\n","\n","df.to_csv('/content/drive/MyDrive/Tesi/Master-Thesis/data/interim/promise-reclass.csv', index=False)\n","df[y_column].value_counts()"],"metadata":{"id":"xvtgI2iTA8Xg","executionInfo":{"status":"ok","timestamp":1701076559188,"user_tz":-60,"elapsed":804,"user":{"displayName":"Marco Calenda","userId":"01086435372740505866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f6a4fa2-2bf5-4c3d-f633-e4c42eee4fbe"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SE    125\n","US     85\n","O      77\n","PE     67\n","Name: Class, dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Load filtered data\n"],"metadata":{"id":"ljrP7x2kpls6"}},{"cell_type":"code","source":["FILTERED_DATASET_PATH = '/content/drive/MyDrive/Tesi/Master-Thesis/data/interim/promise-reclass_filtered.csv'\n","df = pd.read_csv(FILTERED_DATASET_PATH)"],"metadata":{"id":"cx3DEalvzrl3","executionInfo":{"status":"ok","timestamp":1701076572537,"user_tz":-60,"elapsed":741,"user":{"displayName":"Marco Calenda","userId":"01086435372740505866"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# Infrequent words"],"metadata":{"id":"Gq_wKkugqHKq"}},{"cell_type":"code","source":["from nltk.probability import FreqDist\n","from nltk.tokenize import word_tokenize\n","\n","all_words = [word.lower() for tokens in df['RequirementText'].apply(lambda x: word_tokenize(x)) for word in tokens]\n","freq_dist = FreqDist(all_words)\n","one_occ_words = [word for word, freq in freq_dist.items() if freq <= 2]\n","sentence_lengths = df['RequirementText'].apply(lambda x: len(word_tokenize(x)))\n","mean_sentence_length = np.mean(sentence_lengths)\n","\n","print(f\"Number of words appearing once: {len(one_occ_words)}\")\n","print(f\"Mean size of sentences in the dataset: {mean_sentence_length}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoV2xZ0M7Ee5","executionInfo":{"status":"ok","timestamp":1701077059974,"user_tz":-60,"elapsed":327,"user":{"displayName":"Marco Calenda","userId":"01086435372740505866"}},"outputId":"f28de44f-0ce3-497b-e3fd-bf644b2808ab"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words appearing once: 322\n","Mean size of sentences in the dataset: 7.27683615819209\n"]}]},{"cell_type":"markdown","source":["# Text normalization"],"metadata":{"id":"63gEsF9iq0S6"}},{"cell_type":"code","source":["def normalize_text_quantum(text):\n","    return text.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n","\n","def normalize_text_classical(text):\n","    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n","    tokens = word_tokenize(text)\n","\n","    # stop words\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [token for token in tokens if token.lower() not in stop_words]\n","\n","    # lemmatization\n","    lemmatizer = WordNetLemmatizer()\n","    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","\n","    tokens = [token for token in tokens if not (token.isdigit() or len(token) <= 2)]\n","    return \" \".join(tokens)\n","\n","df_normalized_quantum = df.copy()\n","df_normalized_classical = df.copy()\n","\n","df_normalized_quantum[X_column] = df_normalized_quantum[X_column].apply(normalize_text_quantum)\n","df_normalized_classical[X_column] = df_normalized_classical[X_column].apply(normalize_text_classical)\n","\n","df_normalized_quantum.to_csv('/content/drive/MyDrive/Tesi/Master-Thesis/data/processed/quantum.csv', index=False)\n","df_normalized_classical.to_csv('/content/drive/MyDrive/Tesi/Master-Thesis/data/processed/classical.csv', index=False)"],"metadata":{"id":"MOVOMlVOIKpm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [TESTING] Data balancing"],"metadata":{"id":"tfnaHk86r-tK"}},{"cell_type":"code","source":["from imblearn.under_sampling import RandomUnderSampler\n","\n","def binary_balance(df, target_column):\n","    class_elements = df[df[y_column] == target_column]\n","    other_class_elements = df[df[y_column] != target_column]\n","    sampled_data = other_class_elements.sample(n=len(class_elements), random_state=SEED)\n","    return pd.concat([class_elements, sampled_data], ignore_index=True)\n","\n","def multi_balance(df):\n","    X_arr = df[X_column].to_numpy()\n","    y_arr = df[y_column].to_numpy()\n","    rus = RandomUnderSampler(random_state=SEED)\n","    X_resampled, y_resampled = rus.fit_resample(X_arr.reshape(-1, 1), y_arr.reshape(-1, 1))\n","    return pd.DataFrame({X_column: X_resampled.flatten(), y_column: y_resampled.flatten()})\n","\n","df_se_quantum = binary_balance(df_normalized_quantum, 'SE')\n","df_us_quantum = binary_balance(df_normalized_quantum, 'US')\n","df_o_quantum = binary_balance(df_normalized_quantum, 'O')\n","df_pe_quantum = binary_balance(df_normalized_quantum, 'PE')\n","\n","df_se_classical = binary_balance(df_normalized_classical, 'SE')\n","df_us_classical = binary_balance(df_normalized_classical, 'US')\n","df_o_classical = binary_balance(df_normalized_classical, 'O')\n","df_pe_classical = binary_balance(df_normalized_classical, 'PE')\n","\n","df_multi_quantum = multi_balance(df_normalized_quantum)\n","df_multi_classical = multi_balance(df_normalized_classical)"],"metadata":{"id":"8jCKKy0Zc8HZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# custom_primary = '#007FFF'\n","# custom_secondary = '#FF6666'\n","\n","# class_counts = df[y_column].value_counts()\n","# new_class_counts = df_multi_quantum[y_column].value_counts()\n","\n","# fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n","# axs[0].bar(class_counts.index, class_counts, color=custom_primary)\n","# axs[0].set_ylabel('Occurrences')\n","# axs[0].set_title('Before Undersampling')\n","# axs[0].set_xlabel('Class')\n","\n","# axs[1].bar(new_class_counts.index, new_class_counts.values, color=custom_secondary)\n","# axs[1].set_title('After Undersampling')\n","# axs[1].set_xlabel('Class')\n","\n","# plt.tight_layout()\n","# plt.savefig(\"/content/drive/MyDrive/Tesi/Master-Thesis/figures/dataset_preprocess/undersampling.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n","# plt.show()"],"metadata":{"id":"GIWfKyoNBp51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BALANCED_DATA_PATH = '/content/drive/MyDrive/Tesi/Master-Thesis/data/processed/balanced/'\n","\n","df_se_quantum.to_csv(BALANCED_DATA_PATH + 'quantum_SE.csv', index=False)\n","df_us_quantum.to_csv(BALANCED_DATA_PATH + 'quantum_US.csv', index=False)\n","df_o_quantum.to_csv(BALANCED_DATA_PATH + 'quantum_O.csv', index=False)\n","df_pe_quantum.to_csv(BALANCED_DATA_PATH + 'quantum_PE.csv', index=False)\n","\n","\n","df_se_classical.to_csv(BALANCED_DATA_PATH + 'classical_SE.csv', index=False)\n","df_us_classical.to_csv(BALANCED_DATA_PATH + 'classica_US.csv', index=False)\n","df_o_classical.to_csv(BALANCED_DATA_PATH + 'classical_O.csv', index=False)\n","df_pe_classical.to_csv(BALANCED_DATA_PATH + 'classical_PE.csv', index=False)\n","\n","df_multi_quantum.to_csv(BALANCED_DATA_PATH + 'quantum.csv', index=False)\n","df_multi_classical.to_csv(BALANCED_DATA_PATH + 'classical.csv', index=False)"],"metadata":{"id":"9EnsW2ZQZaG_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}